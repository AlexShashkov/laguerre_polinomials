\documentclass[a4paper,12pt]{article}
\usepackage[left=2cm,right=1cm,top=2cm,bottom=2cm]{geometry}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\pagestyle{plain}
\usepackage{fancybox}
\usepackage{bm}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{floatrow}
\usepackage{pdfpages}
\usepackage{ragged2e}
\usepackage{algorithm}
\usepackage{algpseudocode}
\documentclass{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{enumitem}
\usepackage[showframe]{geometry}
\justifying
\usepackage[inkscapeformat=png]{svg}
\usepackage[pageanchor]{hyperref}
\algblock[BLOCK]{parfor}{endparfor}

\begin{document}
\tableofcontents
\hyperpage{}

\newpage
\section{Введение} 
В данной статье приведены две модификации метода Лагерра. Они определяют методы
одновременной аппроксимации всех нулей данного многочлена. Метод Лагерра для аппроксимации нулей многочлена считается
одним из стандартов, по которому следует оценивать другие алгоритмы нахождения нуля. Он характеризуется отличным начальным поведением, глобальной сходимостью для
многочлены только с вещественными корнями, локальная кубическая сходимость к простому корню и
локальная линейная сходимость к кратному корню (см. Ostrowski [1]).
\\
В первом разделе мы рассмотрим вывод метода Лагерра, найденный в Parlett [2].

\\
Во втором разделе мы описываем две
модификации для одновременной аппроксимации всех нулей данного
многочлена. Одна из этих модификаций особенно
подходит для реализации на компьютерах с параллельной обработкой. 

\\
Третий раздел посвящен изучению скорости сходимости модифицированных методов.

% \\
% В четвертом разделе мы рассматриваем критерий остановки, гарантирующий, что итерации не прекратятся до тех пор, пока полученное значение не станет надежным для приближения корня.


\newpage
\section{Теоретическое обоснование}
\subsection{Вывод метода}

Пусть $f(z)$ - комплексный многочлен с корнями $r_1, r_2 \dots r_n$ и пусть $z$ аппроксимирует корень $r_j$ для некоторого фиксированного $j$. Определим
\[S_1(z)=\frac{f'(z)}{f(z)}=\sum_{i=1}^{n} \frac{1}{z-r_j} \eqno (1)\]
и
\[S_2(z)=-\frac{dS_1}{dz}=\frac{(f'(z))^2-f(z)f''(z)}{(f(z))^2}=\sum_{i=1}^{n} \frac{1}{(z-r_j)^2}. \eqno (2)\]

\noindent
Пусть $\alpha(z)=\frac{1}{z-r_j}$ и $\beta(z)+\gamma_i(z)=\frac{1}{z-r_j}$(для $i=1,2,\dots,n, i\neq j$), где $\beta$ это среднее значение коллекции $\frac{1}{z-r_j}, i \neq j$. Ясно, что $\sum_{i=1, i\neq j}^{n}\gamma_i=0$. 

\noindent
Определим
\[\delta^2=\sum_{i=1, i\neq j}^{n}\gamma_i^2. \eqno (3)\]

\noindent
Используя определения $\alpha(z), \beta(z)$ и $\delta^2$, перепишем (1) и (2) в виде
\[S_1=\alpha+(n-1)\beta\ \eqno (4)\]
и
\[S_2=\alpha^2+(n-1)\beta^2+\delta^2 \eqno (5)\]

\noindent
Исключая $\beta$ из (4) и (5) и решая для $\alpha$, получим
\[\alpha=\frac{S_1\pm \sqrt{(n-1)[nS_2-S_1^2-n\delta^2]}}{n}. \eqno (6)\]

\noindent
Поскольку $\alpha=\frac{1}{z-r_j}$ и (6) следует 
\[r_j=z-\frac{n}{S_1\pm \sqrt{(n-1)[nS_2-S_1^2-n\delta^2]}}, \eqno (7)\]

\noindent
где $S_1$, $S_2$ и $\delta^2$ оцениваются по $z$.

Это точное выражение для $r_j$ в терминах аппроксимации $z$. Задавая $\delta^2=0$ в (7), получаем итерационную формулу Лагерра
\[z_j^{(k+1)}=z_j^{(k)}-\frac{n}{S_1\pm \sqrt{(n-1)[nS_2-S_1^2]}}, \eqno (8)\]

\noindent
где $S_1$ и $S_2$ вычислены при $z_j^{(k)}$, текущая аппроксимация к $r_j$, и они определяется (1) и (2), соответственно.
\newpage
\subsection{Две модификации метода Лагерра.}
1. Подставляя 
\[\beta=\frac{1}{n-1} \sum_{i=1, i\neq j}^{n} \frac{1}{z-r_i}\]

\noindent
в (5) и решая для $\delta^2$, мы получаем, используя (2) 
\[\delta^2=\sum_{i=1, i\neq j}^{n} \frac{1}{(z-r_i)^2}-\frac{1}{n-1} \biggr[ \sum_{i=1, i\neq j}^{n} \frac{1}{z-r_i} \biggr]^2=\sum_{i \neq j}\biggr[\frac{1}{z-r_i}-\beta \biggr]^2. \eqno (9)\]

\noindent
Таким образом, $\delta^2$ всегда неотрицательна для действительных $z$ и $r_i$. 

Если бы корни $r_1, \dots, r_{j-1}, r_{j+1}, \dots, r_n$ были известны, то для произвольного $z$, $\delta^2$ можно было бы вычислить из (9) и использовать (7) для получения точного выражения для корня $r_j$ в терминах $S_1$ и $S_2$, вычисленные при $z$ и других корнях. В общем случае это невозможно, поскольку мы не знаем оставшихся $n-1$ корней.

Сформулируем алгоритм, позволяющий аппроксимировать $\delta^2$, одновременно аппроксимируя все корни заданного многочлена $f(z)$. Пусть $z_1^{(k)}, z_2^{(k)}, \dots, z_n^{(k)}$ аппроксимации нулей $r_1, r_2, \dots, r_n$ многочлена $f(z)$, соответственно, и определим
\[\delta_j^{2}=\sum_{i=1, i\neq j}^{n}\biggr[\frac{1}{z_j^{(k)}-z_i^{(k)}}-\beta_j\biggr]^2 \eqno (10)\]

\noindent
где
\[\beta_j=\frac{1}{n-1}\sum_{i=1, i\neq j}^{n}\frac{1}{z_j^{(k)}-z_i^{(k)}}.\]

\noindent
Знаем, что $\delta_j^{2} \approx \delta^2$ вычисляется при $z=z_j^{(k)}$, где $\delta^2$ определяется в (9). Точность этой аппроксимации зависит от точности аппроксимации $z_i^{(k)}$ к $r_i$ $(i=1, \dots, n; i \neq j)$.

Рассмотрим метод Лаггера (8). На практике мы выбираем знак перед квадратным корнем, чтобы сделать меньший шаг $z_j^{(k+1)}-z_j^{(k)}$. Если $f(z)$ вещественное со всеми вещественными корнями, то этот шаг "подрезает" корень $r_j$. А также, $nS_2-S_1^2\geq0$ в вещественном случае.

Если заменим $nS_2-S_1^2$ под квадратным корнем на $nS_2-S_1^2-n\delt^2$, то получим больший шаг, который, согласно (7), и необходим для достижения корня $r_j$.

Аппроксимируем $\delta^2$ величиной $\delta^2_{j}$, заданной в (10), и используем итерационную функцию
\[z_j^{(k+1)}=z_j^{(k)}-\frac{n}{S_1\pm \sqrt{(n-1)[nS_2-S_1^2-n\delta^2_{j}]}}. \eqno (11)\]

\noindent
Этот больший шаг (в общем случае) обеспечивает более близкую аппроксимацию к $r_j$, чем это делал метод Лаггера (8).

Если у нас имеются аппроксимации $z_j^{(k)}$ для $r_j$ для всех $j=1,\dots,n$, мы можем вычислить $\delta^2$ для всех $j$, используя (10). Следовательно, мы можем определить алгоритм для одновременной аппроксимации всех корней. Таким образом, алгоритм является подходящим для реализации на параллельной обработке данных.
% Результирующая итерация является итерацией "типа Якоби", поскольку новое приближение к
% корня получается с помощью старых приближений для других корней.
\newpage
\noindent
2. Рассмотрим теперь модификацию  типа "Гаусс-Зейдель", которая является возможным улучшением как (8), так и (11). Она использует любую новую аппроксимацию, как только она будет найдена. То есть, предположим, что мы использовали (11) с $z_1^{(k)}, z_2^{(k)}, \dots, z_n^{(k)}$ для получения новой аппроксимации $z_1^{(k+1)}.$
Затем мы можем использовать $z_1^{(k+1)}, z_2^{(k)}, \dots, z_n^{(k)}$ вместо $z_1^{(k)}, z_2^{(k)}, \dots, z_n^{(k)}$ для получения новой аппроксимации $z_1^{(k+1)}.$ Для обобщения пусть
\[\delta^{*}_{j}=\sum_{i=1}^{j-1}\biggr[\frac{1}{z^{(k)}_{j}-z^{(k+1)}_{i}}-\beta^{*}_{j}\biggr]^2+\sum_{i=j+1}^{n}\biggr[\frac{1}{z^{(k)}_{j}-z^{(k)}_{i}}-\beta^{*}_{j}\biggr]^2 \eqno (12)\]

\noindent
где
\[\beta^{*}_{j}=\frac{1}{n-1}\biggr[ \sum_{i=1}^{j-1}\frac{1}{z^{(k)}_{j}-z^{(k+1)}_{i}} + \sum_{i=j+1}^{n}\frac{1}{z^{(k)}_{j}-z^{(k)}_{i}} \biggr].\]

\noindent
Если заменим в (11) $\delta_{j}^{2}$ на $\delta_{j}^{*}$, то сможем определить алгоритм, который использует новые аппроксимации $z_{i}^{(k+1)}$ к $r_i$ по мере их поступления вместо того, чтобы ждать пока все $z_{j}^{(k+1)},$ $j=1,2,\dots,n$ будут определены. Поскольку новые $z_{j}^{(k+1)}$, предположительно, являются более точны, чем старые $z_{j}^{(k)}$, то результирующий алгоритм должен сходиться быстрее.

Итерационная формула, полученная в результате этой модификации, имеет вид
\[z_{j}^{(k+1)}=z_{j}^{(k)}-\frac{n}{S_1\pm \sqrt{(n-1)[nS_2-S_1^2-n\delta^{*}_{j}]}} \eqno (13)\]

\noindent
где $S1$ и $S_2$, заданные в (1) и (2), соответственно, вычисляются в $z_{j}^{(k)}$ и $\delta_{j}^{*}$, определенный в (12).

\newpage
\subsection{Исследование скорости сходимости}
Пусть $\varepsilon_{j}^{(k+1)}=z_{j}^{(k+1)}-r_j$ и $\varepsilon_{j}^{(k)}=z_{j}^{(k)}-r_j$. Предположим, что $\delta_{j}^{2}$ в (11) - константа и, что $r_j$ - простой корень. Ранее было показано, что $S_1(z)=\frac{f'(z)}{f(z)}$ и $S_2(z)=\frac{(f'(z))^2-f(z)f''(z)}{(f(z))^2}$. С помощью несложных действий можем показать, что для $j=1,2,\dots,n$
\[\varepsilon_{j}^{(k+1)}=(\varepsilon_{j}^{(k)})^3 \biggr[ \frac{3(f'')^2-4f'f'''}{24(f')^2} -\frac{1}{8} \frac{1}{n-1} \biggl(\frac{f''}{f'}\biggl)^2-\frac{\delta_{j}^{2}}{2} \biggr]+O\Bigl((\varepsilon_{j}^{(k)})^4\Bigl) \eqno (14)\]

\noindent
где $f', f''$ и $f'''$ вычислены при $z=r_j$. Это показывает, что, когда $\delta_{j}^{2}$ любая постоянная величина, (11) определяет итерационную формулу с кубической скоростью сходимости к простым корням. При нулевом значении $\delta_{j}^{2}$ в (14), полученная асимптотическая константа ошибки согласуется с константой метода Лаггера[6].

Если $\delta_{j}^{2}>0$, что имеет место в вещественном случае, рассмотренный во втором разделе, и если оно не слишком велико, то есть, если $\delta_{j}^{2}<2L(r_j)$, где
\[L(r_j)=\frac{3(f'')^2-4f'f'''}{24(f')^2}-\frac{1}{8}\frac{1}{n-1}
\biggl(\frac{f''}{f'}\biggl)^2, \eqno (15)
\]

\noindent
тогда
последовательность $<z_{j}^{(k)}>$, порожденная (11), имеет меньшую асимптотическую константу ошибки, чем
чем соответствующая последовательность, порожденная (8). Это означает, по крайней мере асимптотически,
что итерационная функция (11) с $\delta_{j}^{2}$, определенный в (10), имеет улучшенную сходимость по сравнению с методом Лагерра. То же самое справедливо и для $\delta_{j}^{2}$, заменненого на $\delta_{j}^{*}$, определенный в (12), если $\delta_{j}^{2}<2L(r_j)$.

Рассмотрим скорость сходимости (11), рассматривая $\delta_{j}^{2}$, как функцию от $z$. Знаем, что $\varepsilon_{j}^{(k)}=z_{j}^{(k)}-r_j$, $j=1,2,\dots,n$ и пусть $r_{ij}=r_i-r_j$, тогда можем показать, что
\[\varepsilon_{j}^{(k+1)}=\Bigl(\varepsilon_{j}^{(k)}\Bigl)^3 \biggr[\sum_{i=1, i\neq j}^{n}\frac{\varepsilon_{i}^{(k)}}{r_{ij}^{3}}-\frac{i}{n-1}\biggl(\sum_{i=1, i\neq j}^{n}\frac{1}{r_{ij}}\biggl)\sum_{i=1, i\neq j}^{n}\frac{\varepsilon_{i}^{(k)}}{r_{ij}^{2}}\biggr] \eqno (16)\]

\begin{center}
    + члены высших порядков в $\varepsilon_{j}^{(k)}$ и $\varepsilon_{i}^{(k)}$.
\end{center}

\noindent
Если возьмем $\varepsilon_{i}^{(k)}=\eta_i \varepsilon^{(k)}$, то убедимся в том, что метод, определенный в (11), с $\delta_{j}^{2}$, заданный в (10), имеет по крайней мере сходимость 4-го порядка к простым корням. Исходя из определения (12) о $\delta_{j}^{*}$, следует, что дальнейшее улучшение сходимости будет достигнуто с помощью итерации, определенной в (13).

\newpage
\subsection{Параллельный алгоритм}

Итерационная формула, определенная (11), кажется подходящей в качестве параллельного алгоритма для одновременного определения всех корней заданного многочлена степени $n$. 

Известно, что $\delta_{j}^{2}$, определенный (10), сходится к $\delta^{2}$, определенный (9), вычисленный при $z=r_j$ как $z_{i}^{(k)}$ сходящийся к $r_i$, $i=1,\dots,n$. Поэтому (11) как функция от $z_{i}^{(k)}$, $i=1,2,\dots,n$ сходится к точному выражению для корня $r_j$, $j=1,2,\dots,n$ и имеет отличное асимптотическое поведение. Кроме того, метод Лагерра имеет хорошее начальное поведение в следующем смысле: даже если начальная оценка корня достаточно велика, то один шаг метода Лагерра дает новую оценку, "достаточно близкую" к корню[9].

Одним из способов описания такого поведения состоит в следующем. Предположим, что в (8) допускаем, что $z_{j}^{(k)}$ становится бесконечно большой величиной. Посколько $z_{j}^{(k)} \to \infty$, $z_{j}^{(k+1)}$ приближается к конечному пределу. В частности, если
\[f(z)=\sum_{i=0}^{n}a_iz^i,\]

\noindent
тогда
\[\lim_{z_{j}^{(k)}\to\infty}=\frac{1}{na_n}\lbrace [(n-1)^2a_{n-1}^{2}-2n(n-1)a_na_{n-2}]^{\frac{1}{2}}-a_{n-1}\rbrace.\]

Наша модификация (11) обладает тем свойством, что все $z_{i}^{(k)}$ для $i=1,\dots,n$ $(i\neq j)$ остаются конечными при $z_{j}^{(k)} \to \infty$.


\newpage
\section{Описание работы алгоритма}
% Пусть $p(z)$ - полином следующего вида:
% $$p(z) = a_0 + a_{1}z + \text{···} + a^{m}z^{m} \qquad (1)$$
% Мы стремимися вычислить корни $p(z)$ и для этого необходимо выполнить следующие пункты:
% \begin{enumerate}
%     \item Найти начальное приближение:
%         \begin{algorithm}
%             \caption{Вычисление начального приближения}\label{alg:Example}
%             \begin{algorithmic}
%             \State \text{Вычислить} $\hat{k}_1,\text{...}, \hat{k}_\hat{q}$ \text{с помощью алгоритма монотонной цепи Эндрю} 
%             \For{$i=1$ to $\hat{q}-1$}
%                 \State $n=\hat{k}_{i+1}-\hat{k}_i$
%                 \State $u_{\hat{k_{i+1}}}=\left| \frac{a_{\hat{k}_i}}{a_{\hat{k}_{i+1}}} \right|^{1/n}$
%                 \For{$j=1$ to $n$}
%                     \State $z_{\hat{k}_{i+1}}e^{\left(\frac{2\pi}{n}j + \frac{2\pi}{m} + \sigma\right)i}$
%                 \EndFor
%             \EndFor 
%             \end{algorithmic}
%         \end{algorithm}

%         Для вычисления $\hat{k}_1,\text{...}, \hat{k}_\hat{q}$ используется следующий алгоритм:
%         \begin{algorithm}[H]
%             \caption{Алгоритм Эндрю}\label{alg:Example}
%             \begin{algorithmic}
%             \State $P\gets \text{список из $m$ точек в двумерной плоскости}$
%             \State \text{Отсортируйте точки P по x-координате (в случае совпадения сортируйте по y-координате)}
%             \Function{orientation}{Point p, Point q, Point r}
%                 \State val = (q.y - p.y) * (r.x - q.x) - (q.x - p.x) * (r.y - q.y)
%                 \If{val = 0}
%                     \State return 0
%                 \ElsIf{val > 0}
%                     \State return 1
%                 \Else
%                     \State return 2
%                 \EndIf
%             \EndFunction
    
    
%             \For{$i=1$ to $m$}
%             \State $p = P[i]$
%             \While{len(L\_upper) >= 2 and orientation(nextToTop(L\_upper), L\_upper[-1], p) != 2}
%                 \State L\_upper.pop()
%             \EndWhile
%             \State L\_upper.append(p)
%             \While{len(L\_lower) >= 2 and orientation(nextToTop(L\_lower), L\_lower[-1], p) != 1}
%                 \State L\_lower.pop()
%             \EndWhile
%             \State L\_lower.append(p)
%             \EndFor
%             \State hull = L\_upper + L\_lower[::-1]
%             \end{algorithmic}
%         \end{algorithm}



%     \item Обновлять начальное приближение, пока оно не станет "достаточно близко"\ к корням полинома, или пока не пройдет определенное число итераций.
%         \begin{enumerate}
%             \item Последовательный подход:
%             \begin{algorithm}[H]
%                 \caption{Последовательный подход}\label{alg:Example}
%                 \begin{algorithmic}
%                 \State $(z_1, \text{...}, z_m)\gets\text{Начальная аппроксимация полученная с помощью Алгоритма 1}$
%                 \While{$i < $ \text{itmax}}
%                     \For{$j=1$ to $m$}
%                         \If{$z_j$ недостаточно близок к $\zeta_j$}
%                             \State Вычислить корни $Q_j(\lambda)$ с помощью $(2)$, используя $(4)$
%                             \State $z_j \gets \text{корень, который максимизирует знаменатель в } (2)$
%                         \EndIf
%                     \EndFor
%                     \State $i \gets i+1$
%                 \EndWhile
%                 \end{algorithmic}
%             \end{algorithm} 


%             \item Параллельный подход:
%             \begin{algorithm}[H]
%                 \caption{Параллельный подход}\label{alg:Example}
%                 \begin{algorithmic}
%                 \State $(z_1, \text{...}, z_m)\gets\text{Начальная аппроксимация полученная с помощью Алгоритма 1}$
%                 \While{$i < $ \text{itmax}}
%                     \parfor{ $j=1$ to $m$} \textbf{do}
%                         \If{$z_j$ недостаточно близок к $\zeta_j$}
%                             \State Вычислить $G_j$ и $H_j$ с помощью $(4)$ и сохранить
%                         \EndIf
%                     \endparfor
%                     \parfor{ $j=1$ to $m$ \textbf{do}}
%                         \If{$z_j$ недостаточно близок к $\zeta_j$}
%                             \State Вычислить корни $Q_j(\lambda)$ с помощью $(2)$, используя $G_j$ и $H_j$
%                             \State $z_j \gets \text{корень, который максимизирует знаменатель в } (2)$
%                         \EndIf
%                     \endparfor
%                     \State $i\gets i+1$
%                 \EndWhile
%                 \end{algorithmic}
%             \end{algorithm} 
            
%         \end{enumerate}
        
% \end{enumerate}



\newpage

\section{Список литературы}
% \begin{enumerate}
%     \item Petkovic, M.S., Ilic, S., Trickovic, S.: A family of simultaneous zero finding methods. Comput. Math. Appl. 34(10), 49–59 (1997)
%     \item Bini, D.A.: Numerical computation of polynomial zeros by means of Aberth’s method. Numer. Algor. 13, 179–200 (1996)
%     \item Pellet, A.E.: Sur un mode de separation des racines des equations et la formule de lagrange. Bull. Sci. Math. 5(2), 393–395 (1881)
% \end{enumerate}


\end{document}
